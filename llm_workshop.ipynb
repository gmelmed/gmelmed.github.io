{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GH68QND6Dc1",
        "outputId": "aa024a60-0cca-4145-94cf-9fcc1b288cde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "selenium 4.23.0 requires typing_extensions~=4.9.0, but you have typing-extensions 4.12.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install openai==1.55.3 httpx==0.27.2 --force-reinstall --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fAUfxGWQ4hNA"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'TypeIs' from 'typing_extensions' (/Users/gabrielmelmed/Library/Python/3.9/lib/python/site-packages/typing_extensions.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/__init__.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_os\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m override\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m types\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NOT_GIVEN, NoneType, NotGiven, Transport, ProxiesTypes\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m file_from_path\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/types/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Batch \u001b[38;5;28;01mas\u001b[39;00m Batch\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image \u001b[38;5;28;01mas\u001b[39;00m Image\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model \u001b[38;5;28;01mas\u001b[39;00m Model\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/types/batch.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Optional\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Literal\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch_error\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BatchError\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch_request_counts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BatchRequestCounts\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/_models.py:24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerics\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfields\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FieldInfo\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     27\u001b[0m     Body,\n\u001b[1;32m     28\u001b[0m     IncEx,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     HttpxRequestFiles,\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     38\u001b[0m     PropertyInfo,\n\u001b[1;32m     39\u001b[0m     is_list,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m     strip_annotated_type,\n\u001b[1;32m     51\u001b[0m )\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pydantic/fields.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic_core\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PydanticUndefined\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Literal, TypeAlias, Unpack, deprecated\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m types\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _decorators, _fields, _generics, _internal_dataclass, _repr, _typing_extra, _utils\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_namespace_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GlobalsNamespace, MappingNamespace\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pydantic/types.py:39\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic_core\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CoreSchema, PydanticCustomError, SchemaSerializer, core_schema\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Annotated, Literal, Protocol, TypeAlias, TypeAliasType, deprecated\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _core_utils, _fields, _internal_dataclass, _typing_extra, _utils, _validators\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_migration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m getattr_migration\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mannotated_handlers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GetCoreSchemaHandler, GetJsonSchemaHandler\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pydantic/_internal/_core_utils.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TypeGuard, get_args, get_origin\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PydanticUserError\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _repr\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core_metadata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CoreMetadata\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing_extra\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_generic_alias, is_type_alias_type\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pydantic/_internal/_repr.py:11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _typing_extra\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typing\u001b[38;5;241m.\u001b[39mTYPE_CHECKING:\n\u001b[1;32m     14\u001b[0m     ReprArgs: typing_extensions\u001b[38;5;241m.\u001b[39mTypeAlias \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtyping.Iterable[tuple[str | None, Any]]\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pydantic/_internal/_typing_extra.py:15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Any, Callable\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TypeIs, deprecated, get_args, get_origin\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_namespace_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GlobalsNamespace, MappingNamespace, NsResolver, get_module_ns_of\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m<\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m10\u001b[39m):\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'TypeIs' from 'typing_extensions' (/Users/gabrielmelmed/Library/Python/3.9/lib/python/site-packages/typing_extensions.py)"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "import json\n",
        "import requests\n",
        "import pandas\n",
        "from markdown import markdown\n",
        "from IPython.display import Markdown\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlIWj0Xh4lxH"
      },
      "source": [
        "# Interacting with LLMs\n",
        "\n",
        "In this class, we'll use the GPT API via OpenAI's package.\n",
        "</br></br>\n",
        "First we need to setup the package with an API key. We're using a temporary API from the Economics Observatory to avoid the need to sign up for your own OpenAI key.\n",
        "\n",
        "This key is limited:\n",
        "- Maximum spend of <$1 total\n",
        "- Restricted to gpt-4o-mini\n",
        "- No support for images, fine-tuning, etc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHjPIMw24mG_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uBq0zpqR4m_w"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'OpenAI' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m(\n\u001b[1;32m      2\u001b[0m     base_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://qkn7siqnh6.execute-api.eu-west-2.amazonaws.com/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m# If you are using the OpenAI API directly, you'd omit this line\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgmelmed\u001b[39m\u001b[38;5;124m\"\u001b[39m                                               \u001b[38;5;66;03m# ... and use an api_key direct from OpenAI\u001b[39;00m\n\u001b[1;32m      4\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'OpenAI' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://qkn7siqnh6.execute-api.eu-west-2.amazonaws.com/\", # If you are using the OpenAI API directly, you'd omit this line\n",
        "    api_key=\"gmelmed\"                                               # ... and use an api_key direct from OpenAI\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRh1McVW4odF"
      },
      "source": [
        "</br></br>\n",
        "\n",
        "We can now interact with the LLM with just a few lines of code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "qNMYOpph4pGW",
        "outputId": "f65c1c7b-fbea-45bf-d308-19f6dd00a76a"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'client' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-1c286db2da60>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Write a haiku about the LSE centre building.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4o-mini\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     messages=[\n",
            "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
          ]
        }
      ],
      "source": [
        "prompt = \"Write a haiku about the LSE centre building.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a critically acclaimed poet.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt},\n",
        "    ],\n",
        ")\n",
        "\n",
        "response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzOVLEuW4vyE"
      },
      "source": [
        "# Using the API: Source synthesis\n",
        "\n",
        "</br></br>\n",
        "\n",
        "LLMs generates text in response to a prompt. They're a useful tool for automating the extraction of 'fuzzy' information from text - that is information that is not easily quantified or categorised by a computer. For example, it's difficult to write a program that can extract the main arguments from a text, or the ingredients from a recipe.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgtb83454xlD"
      },
      "outputs": [],
      "source": [
        "debate = \"\"\"\n",
        "James Cartlidge\n",
        "(South Suffolk) (Con)\n",
        "(Urgent Question): To ask the Secretary of State for Defence if he will make a statement on the impact of the Government’s Chagos negotiations on the UK-US defence relationship.\n",
        "The Minister for the Armed Forces\n",
        "(Luke Pollard)\n",
        " Share this specific contribution\n",
        "I congratulate the hon. Gentleman on securing this urgent question. The Secretary of State has asked me to respond on behalf of the Department.\n",
        "\n",
        "On 3 October, the UK and Mauritius reached an historic agreement to secure the important UK-US military base on Diego Garcia, which plays a crucial role in regional and international security. The agreement secures the effective operation of the joint facility on Diego Garcia well into the next century. The agreement is strongly supported by our closest friends and allies, including the United States. It has been supported by all relevant US Departments and agencies, following a rigorous scrutiny process.\n",
        "\n",
        "This base is a key part of UK-US defence relationships, as it enables the United Kingdom and the United States to support operations that demonstrate our shared commitments to regional stability, provide a rapid response to crises and counter some of the most challenging security threats we face. The President of the United States applauded the agreement. To quote him directly:\n",
        "\n",
        "“It is a clear demonstration that through diplomacy and partnership, countries can overcome long-standing historical challenges to reach peaceful and mutually beneficial outcomes.”\n",
        "\n",
        "Several other countries and organisations, including India, the African Union, the UN Secretary-General and others, have welcomed and applauded this historic political agreement.\n",
        "\n",
        "Our primary goal throughout these negotiations, which started over two years ago under the previous Government, was to protect the joint UK-US military base on Diego Garcia. There will be clear commitments in the treaty to robust security arrangements, including arrangements preventing the presence of foreign security forces on the outer islands, so that the base can continue to operate securely and effectively. The operation of the base will continue unchanged, with strong protections from malign influence.\n",
        "\n",
        "For the first time in 50 years, the base will be undisputed and legally secure. Continued uncertainty would be a gift to our adversaries. That is why the agreement has been welcomed by all parts of the US system, and other critical regional security partners. Agreeing the deal now, on our terms, meant that we were able to secure strong protections that will allow the base to operate as it has done. We look forward to engaging with the upcoming US Administration on this and many other aspects of the UK-US special relationship.\n",
        "\n",
        "Finally, hon. Members can be reassured that the long-term protection of the base on Diego Garcia has been the shared UK and US priority throughout, and this agreement secures its future. We would not have signed off on an agreement that compromised any of our security interests, or those of the US and our allies and partners.\n",
        "Column 26is located here\n",
        "James Cartlidge\n",
        " Share this specific contribution\n",
        "Thank you, Mr Speaker, for granting this urgent question.\n",
        "\n",
        "At a time when we face the most challenging military threats for years, surely our top priority should be to preserve the strongest possible US-UK relations, given that this is so vital to our national security, yet it appears that the Government are seeking to agree a deal surrendering the sovereignty of the Chagos islands before President Trump is formally in post. We know that the new US Administration are concerned about the Government’s deal because presumptive nominee US Secretary of State Marco Rubio has said that the deal\n",
        "\n",
        "“poses a serious threat to our national security interests”.\n",
        "\n",
        "He has also suggested that\n",
        "\n",
        "“it would provide an opportunity for communist China to gain valuable intelligence on our naval support facility”.\n",
        "\n",
        "Let us be clear: our military base on Diego Garcia is a vital strategic asset for the UK in the Indian ocean, and it is critical to our presence and posture in the Indo-Pacific region. In particular, it is an especially important base for the United States, and we believe that anything that damages its defence posture, particularly in relation to China, also undermines our national security. We understand that the new Mauritius Government have now launched a review of the deal.\n",
        "\n",
        "Will the Minister therefore confirm that the Government’s policy really is to try to rush through their Chagos deal before President Trump’s inauguration? Does he not see how that would be hugely disrespectful to the new Administration and President Trump’s democratic mandate? Given that we now know it is common for the MOD to state the cost of overseas bases, will he be transparent and finally tell the House how much we will have to pay to rent back the vital military base that we currently own?\n",
        "\n",
        "Finally, although we would prefer the Government to cancel the whole deal, at the very least will the Minister pause any further ratification until the new US Administration are in place and the Mauritius Government have concluded their review?\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are an analyst who summarises parliamentary debates.\"},\n",
        "        {\"role\": \"user\", \"content\": \" Summarise this debate. Give me very brief responses with heading for what the debate is about, and what the main arguments are (with who made them).\" + debate},\n",
        "    ],\n",
        ")\n",
        "\n",
        "Markdown(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrZE-eCR4z1I"
      },
      "source": [
        "</br></br>\n",
        "</br></br>\n",
        "\n",
        "## Example: Identifying ingredients in a recipe\n",
        "\n",
        "In this example, we'll use an LLM to parse a natural language recipe. We'll extract the ingredients, kitchen appliances required, cooking method and a suggestion for how to make it healthier.\n",
        "\n",
        "</br></br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwXleQS340Fm"
      },
      "outputs": [],
      "source": [
        "recipe = \"\"\"\n",
        "# Miso-Butter Roast Chicken With Acorn Squash Panzanella\n",
        "\n",
        "Pat chicken dry with paper towels, season all over with 2 tsp. salt, and tie legs together with kitchen twine. Let sit at room temperature 1 hour.\n",
        "Meanwhile, halve squash and scoop out seeds. Run a vegetable peeler along ridges of squash halves to remove skin. Cut each half into \\u00bd\\\"-thick wedges; arrange on a rimmed baking sheet.\n",
        "Combine sage, rosemary, and 6 Tbsp. melted butter in a large bowl; pour half of mixture over squash on baking sheet. Sprinkle squash with allspice, red pepper flakes, and \\u00bd tsp. salt and season with black pepper; toss to coat.\n",
        "Add bread, apples, oil, and \\u00bc tsp. salt to remaining herb butter in bowl; season with black pepper and toss to combine. Set aside.\n",
        "Place onion and vinegar in a small bowl; season with salt and toss to coat. Let sit, tossing occasionally, until ready to serve.\n",
        "Place a rack in middle and lower third of oven; preheat to 425\\u00b0F. Mix miso and 3 Tbsp. room-temperature butter in a small bowl until smooth. Pat chicken dry with paper towels, then rub or brush all over with miso butter. Place chicken in a large cast-iron skillet and roast on middle rack until an instant-read thermometer inserted into the thickest part of breast registers 155\\u00b0F, 50\\u201360 minutes. (Temperature will climb to 165\\u00b0F while chicken rests.) Let chicken rest in skillet at least 5 minutes, then transfer to a plate; reserve skillet.\n",
        "Meanwhile, roast squash on lower rack until mostly tender, about 25 minutes. Remove from oven and scatter reserved bread mixture over, spreading into as even a layer as you can manage. Return to oven and roast until bread is golden brown and crisp and apples are tender, about 15 minutes. Remove from oven, drain pickled onions, and toss to combine. Transfer to a serving dish.\n",
        "Using your fingers, mash flour and butter in a small bowl to combine.\n",
        "Set reserved skillet with chicken drippings over medium heat. You should have about \\u00bc cup, but a little over or under is all good. (If you have significantly more, drain off and set excess aside.) Add wine and cook, stirring often and scraping up any browned bits with a wooden spoon, until bits are loosened and wine is reduced by about half (you should be able to smell the wine), about 2 minutes. Add butter mixture; cook, stirring often, until a smooth paste forms, about 2 minutes. Add broth and any reserved drippings and cook, stirring constantly, until combined and thickened, 6\\u20138 minutes. Remove from heat and stir in miso. Taste and season with salt and black pepper.\n",
        "Serve chicken with gravy and squash panzanella alongside.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6L8QydD415w"
      },
      "outputs": [],
      "source": [
        "prompt = \"From this recipe, tell me what are the ingredients and kitchen appliances needed? Give me a suggestion of how to make it healthier. Recipe:\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are an assistant that summarises recipes. Return brief bullet points for responses.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt + recipe},\n",
        "    ]\n",
        ")\n",
        "\n",
        "Markdown(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31-IIFkC428V"
      },
      "source": [
        "</br></br>\n",
        "\n",
        "## Structuring the prompt and response\n",
        "\n",
        "This is great, but we've given the LLM normal unstructured text and got back only marginally more structured text. We can do better by giving the LLM instructions to return data in a structured format - JSON. This will allow us to easily extract the information we want from the response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8Oqk_TG5K0B"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"From this recipe, extract the following details and return them in a structured JSON format:\n",
        "1. A list of ingredients.\n",
        "2. A list of kitchen appliances required.\n",
        "3. A suggestion on how to make the recipe healthier.\n",
        "\n",
        "The response **must** follow this exact JSON structure:\n",
        "{\n",
        "    \"ingredients\": [\"List of ingredients as strings\"],\n",
        "    \"kitchen_appliances\": [\"List of kitchen appliances as strings\"],\n",
        "    \"health_suggestion\": \"A single string suggestion to make the recipe healthier\"\n",
        "}\n",
        "\n",
        "Recipe:\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a JSON generator for recipes. Always return JSON responses following the specified format.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt + recipe},\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Print the JSON response\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDKmVeDt5NIp"
      },
      "source": [
        "The response we get back is still just text, but we can turn it into a JSON object with a few lines of code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyyWtQRX5N5g"
      },
      "outputs": [],
      "source": [
        "parsed_recipe = json.loads(response.choices[0].message.content)\n",
        "parsed_recipe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CkNMfRB5TwY"
      },
      "source": [
        "### Exercise: Customise the prompt\n",
        "\n",
        "What else can we learn about the recipe? Add more questions to the prompt to extract more information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPmindBA43Kl"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oNW7Q0H5VIK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqZbzmMJ5WIh"
      },
      "source": [
        "# Looping over multiple recipes\n",
        "\n",
        "We've learnt about one recipe but the value of LLMs come from their ability to process large amounts of text quickly. We can loop over multiple recipes and extract the information we want.\n",
        "\n",
        "</br></br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_Hk7Bbl5YF6"
      },
      "source": [
        "recipes.json contains 5000 recipes. We'll loop over some to parse their information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pz8g3q6Q5Wdi"
      },
      "outputs": [],
      "source": [
        "\n",
        "req = requests.get(\"https://raw.githubusercontent.com/jhellingsdata/RADataHub/refs/heads/main/misc/LLM_practical/recipes.json\")\n",
        "recipes = req.json()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8rlzW245b7m"
      },
      "source": [
        "How do these recipes look?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "G1hYZyaT5aAe",
        "outputId": "9592df06-adb7-4d5e-c5ee-127565e8d963"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'# Stuffed Eggplants and Zucchini in a Rich Tomato Sauce (Baatingan w Kusaa Bil Banadoura)\\n\\n\\n## Instructions\\n\\nTo make the sauce, put the oil into a saucepan or casserole pan with a lid—about 10 inches/25cm wide—and place over medium heat. Add the onions and cook for about 10 minutes, stirring frequently, until soft and caramelized. Add the rest of the sauce ingredients, along with 2½ tsp of salt and a good grind of black pepper. Simmer over medium heat for about 10 minutes, stirring from time to time, then remove from the heat and set aside.\\nTo make the stuffing, while the sauce is cooking, place all the ingredients in a large bowl with 1½ tsp of salt and a good grind of black pepper. Mix well, using your hands to make sure that everything is well incorporated. If making in advance, keep in the fridge until ready to use.\\nTrim the stalks from the eggplants, then insert a manakra (or peeler or corer) into the eggplant; you want it to be very close to the skin—about ⅛ inch/3mm away—but not so close that it tears and won’t hold its shape when it’s stuffed. Scoop out the flesh to create a generous cavity. You don’t need the flesh anymore, but keep it for another recipe; it can be cut into cubes and steamed or added to your next omelette. If your eggplants are particularly large, slice them in half, crosswise, and scoop out the flesh using a regular small serrated knife—be sure to keep one end of each half intact, so that the stuffing does not fall out!\\nUse the manakra or a swivel peeler to scoop out the zucchini flesh. Keep about ⅛ inch/3mm of flesh attached to the skin inside the zucchini and about ½ inch/1cm from the end intact—they need to be robust enough to keep the stuffing inside. Again, keep the scooped-out flesh to use elsewhere.\\nUsing your hands, so that you can push in a bit of stuffing at a time, fill all the eggplant and zucchini cavities. Stop filling them about ½ inch/1cm from the top of each vegetable; the stuffing needs some space to expand inside the vegetables when they are cooking.\\nGently lower the stuffed vegetables into the sauce. They won’t fit in a single layer, but try to avoid too much overlap and submerge them in the sauce as much as you can. Return the sauce to medium heat and, once simmering, decrease the heat to low. Cover the pan and simmer very gently for 90 minutes, or until the rice is completely cooked through and soft—test if it is ready by sticking a knife into the middle of one of the vegetables; it should go in very easily. Don’t worry if some of the rice/stuffing spills into the tomato sauce, this can happen and it will be fine when served.\\nTo make the adha, meanwhile, put the oil into a small frying pan and place over medium heat. After about 1 minute, add the garlic and decrease the heat to medium-low. Cook for about 5 minutes, stirring very often, until the garlic is golden and crispy. Keep a close eye on the pan here; you don’t want the oil to get too hot and for the garlic to burn. Reserving the oil as you pour, strain the garlic through a sieve. Set the garlic aside—it will crisp up as it cools down—and return the oil to the pan. Add the coriander seeds and chile and cook for about 1 minute, stirring a few times, until fragrant. Remove from the heat, transfer to a separate bowl, and set aside until needed.\\nWhen the vegetables are cooked and the sauce is thick and rich (but still pourable), use a slotted spoon to carefully lift the vegetables out of the pan. Pour the sauce onto a large serving platter (or individual serving plates) with a rim and top with the stuffed vegetables. Spoon on the adha—the coriander-chile oil first, followed by the fried garlic—then sprinkle with the fresh herbs and green onion. Serve warm or at room temperature, with the yogurt spooned alongside.'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "recipes[100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGAQhtf35dVs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSXHEleZ5eOb"
      },
      "source": [
        "Now we can prepare our loop to extract the information we want from each recipe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "eEegofAj5fGP",
        "outputId": "37b4ecdf-0775-431e-cac7-fbb651276a08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing recipe 1 of 5000\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'client' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-1c79237b76b5>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m             Recipe:\"\"\"\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4o-mini\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         response_format={\n",
            "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
          ]
        }
      ],
      "source": [
        "openai_responses = []\n",
        "\n",
        "for i, recipe in enumerate(recipes[:10]):\n",
        "    print(f\"Processing recipe {i+1} of {len(recipes)}\")\n",
        "    prompt = \"\"\"From this recipe, extract the following details and return them in a structured JSON format:\n",
        "        1. Title of the recipe.\n",
        "        2. The cuisine of the recipe.\n",
        "        3. A list of kitchen appliances required.\n",
        "        4. Is this recipe vegetarian or not?\n",
        "        5. A suggestion on how to make the recipe healthier.\n",
        "        6. An int indicator (1-10) of how easy the recipe is to make.\n",
        "        7. An estimated time to prepare the recipe (minutes).\n",
        "\n",
        "        The response **must** follow this exact JSON structure:\n",
        "        {\n",
        "            \"title\": \"Title of the recipe as a string\",\n",
        "            \"cuisine\": \"Cuisine of the recipe as a string\",\n",
        "            \"ingredients\": [\"List of ingredients as strings\"],\n",
        "            \"kitchen_appliances\": [\"List of kitchen appliances as strings\"],\n",
        "            \"vegetarian\": \"Boolean value indicating if the recipe is vegetarian or not\",\n",
        "            \"health_suggestion\": \"A single string suggestion to make the recipe healthier\",\n",
        "            \"difficulty\": \"An int indicator (1-10) of how easy the recipe is to make\"\n",
        "            \"prep_time\": \"An int indicating the estimated time in minutes to prepare the recipe (minutes)\"\n",
        "        }\n",
        "\n",
        "            Recipe:\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        response_format={\n",
        "            \"type\": \"json_object\"\n",
        "        },\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a JSON generator for recipes. Always return JSON responses following the specified format.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt + recipe},\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    openai_responses.append(json.loads(response.choices[0].message.content))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlxNCZDC5h7-"
      },
      "source": [
        "Let's take a look at some of them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZMi6CZ95i0l"
      },
      "outputs": [],
      "source": [
        "openai_responses[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp8ze5bB5lKf"
      },
      "source": [
        "We've parsed some recipes!\n",
        "\n",
        "Earlier, I processed the whole dataset. Let's load this file to continue our analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10ms-cPy5pQE"
      },
      "outputs": [],
      "source": [
        "req = requests.get(\"https://raw.githubusercontent.com/jhellingsdata/RADataHub/refs/heads/main/misc/LLM_practical/full_5k-recipe_responses.json\")\n",
        "openai_responses = req.json()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rB3PWilh5spb"
      },
      "source": [
        "## Challenge: What charts can you make from this?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lQACTNA5q3L"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
